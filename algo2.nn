% Algorithmique et structures de données 2 de Paul CALDERON est mis à disposition
% selon les termes de la licence Creative Commons Attribution - Partage dans les
% Mêmes Conditions 4.0 International. Pour accéder à une copie de cette licence,
% merci de vous rendre à l'adresse suivante
% http://creativecommons.org/licenses/by-sa/4.0/ ou envoyez un courrier à Creative
% Commons, 444 Castro Street, Suite 900, Mountain View, California, 94041, USA.



# Algorithmique et structures de données 2

## Analyse du coût d'un algorithme

### La complexité

Regarder une vidéo sur smartphone avec une latence de 10 secondes, c'est pas
terrible...


https://www.youtube.com/watch?feature=player_embedded&v=QS6ywFGcLSk

Parmi les facteurs de la latence se trouve la rapidité d’exécution.  La
complexité en temps vise à quantifier cette vitesse pour nous permettre de
choisir des algorithmes adéquates.  C'est à vous de choisir raisonnablement la
bonne mesure de complexité en fonction du problème.

À partir du concept de comportement asymptotique, nous présentons les mesures de
complexités suivantes:


- **Pire cas**

- **Meilleur cas**

- **Coût en moyenne**

- **Coût amorti**




### Comportement asymptotique

La complexité s'exprime asymptotiquement (lorsque les données tendent vers
l'infini) pour cela on va utiliser les notations suivantes. Si $$f, g$$ sont des
fonctions alors:

$$f=O(g)$$ si il existe $$a>0 $$ tel que pour tout $$x$$, $$|f(x)| < a |g(x)|$$

$$f=\Omega (g)$$ si il existe $$a>0 $$ tel que pour tout $$x$$, $$|g(x)| < a |f(x)|$$

$$f=\Theta (g)$$ si il existe $$a>0$$ et $$b>0$$ tel que pour tout $$x$$ on a :
$$a |g(x)| < |f(x)| < a |g(x)|$$


### Pire cas

Pour certain argument l'algorithme peut prendre plus de temps. Le pire cas correspond à la meilleure majoration du nombre de calculs de l'algorithme.



### Meilleur cas

Pour certain argument l'algorithme peut prendre moins de temps. Le meilleur cas correspond à la meilleure minoration du nombre de calculs de l'algorithme.



### Coût en moyenne

Le coût en moyenne d'un algorithme est le coût que l'on peut espérer avoir lors de l'execution de l'algorithme.



### Coût amorti

Un coût amorti d'un algorithme est la quantité moyenne d'opérations des executions successifs de celui-ci.

Deux manières de le calculer:

- la méthode des agrégats

- la méthode par potentiels

Calculer le coût amorti revient donc parfois à choisir entre ces deux
méthodes.


#### Méthode par agrégats

Dans l'analyse par agrégat on va montrer que pour toutes suites de n opérations
on prend un temps $$T_n$$ et calculer le rapport $$\frac{T_n}{n}$$, c'est le
coût amorti.



#### Méthode par potentiels

A chaque série de i opérations on associe une valeur $$\phi _i$$ qui est le
potentiel en i.  Le coût amorti de l'opération i est alors : $$C_i^{amortie} =
C_i+ \phi _i - \phi _{i-1}$$ \ le coût amorti des n opérations est :
$$C_{amortie} = \sum_{i=1}^n C_i^{amortie} = \sum_{i=1}^n (C_i+ \phi _i - \phi
_{i-1}) = \sum_{i=1}^n C_i+ \phi _n - \phi _{0}$$



~~~ question

Calculer la complexité en fonction du nombre de comparaison dans le pire cas,
dans le meilleur cas et la complexité moyenne de l'algorithme suivant.

```
T tableau indicé de 1 à n, x
a = T[0]
k = 0

Tant que a != x et k <= n Faire:
    a = T[n]
    k = k+1
```
~~~

~~~ answer

- **meilleur cas** : `T[0] = x`, il n'y a aucun parcours de la boucle,
    complexité : $$O(1)$$

- **pire cas** x n'est pas présent dans le tableau, on parcourt n+1 fois la
    boucle en effectuant toujours deux comparaisons, complexité : $$O(n)$$

- **coût moyen** : On peut faire l'hypothèse que la probabilité que la première
    occurrence de x dans T à la case i est $$\frac{1}{n+1}$$.

    Si x apparaît à la case i alors 2(i+1) opérations de comparaisons sont
    effectuées.

    On peut donc écrire : $$C_{moyen} = \sum_{i=0}^{n} c(i).p(i)$$ avec
    $$c(i)=2(i+1)$$ et $$(p(i)=p= \frac{1}{n+1}$$ \ donc $$C_{moyen} = 2(n+1) =
    O(n)$$

~~~



~~~ question

Soit incr, la fonction incrémentant de un un nombre binaire sur n bits. Quel est
le pire cas, le meilleur cas ?  Quel est le coût amorti de la fonction incr ?

~~~

~~~ answer

- **meilleur cas** : le bit de poids faible est à 0, le coût est alors constant.

- **pire cas** tout les bits sont à un, il faut donc parcourir tout le nombre
    pour propager la retenue, coût : $$O(n)$$.

- **coût amorti** : Sur k appels à incr, comptons le nombre de fois oû le bit i
  change de valeur.

  le bit 1 change à chaque appel de incr donc k fois le bit 2 change une fois
  sur deux donc $$ int(k/2)$$ , (int : partie entière inférieure).

  donc le bit i change de valeur $$int(\frac{k}{2^{i-1}})$$ D’où : $$C_{amorti}
  = \frac{1}{k} \sum_{i=1}^{k} int(\frac{k}{2^{i-1}}) \leq \sum_{i>0}
  \frac{1}{2^{i-1}} \leq 2$$

  Le coût amorti est donc en $$O(1)$$.

~~~



## Structures de données

Les sites internets tel que Wikipédia gère beaucoup de données, et on est content de pouvoir accéder à ces données de manière instantanée.

La raison de cette rapidité est l'utilisation judicieuse de différentes structures de données.

Pour chaque structures de données on doit pouvoir **rechercher, insérer, supprimer** un élément.

Cette partie traitera différentes structures et le coût des fonctions rechercher, insérer et supprimer.

### Tableau

Un tableau est une juxtaposition de données dans un espace de taille fini. Les données sont accessibles par leur index (ou indice). Les éléments placé à un indice donné sont accessibles immédiatement.

Le tableau peut être soit trié, soit non trié.

Les performances des tableaux seront étudiés dans le cas où il n'existe pas de bijection immédiate entre un élément et sont index.

#### Tableau non trié : 

Ce type de tableau est utilisé lorsque l'ordre d'apparition des éléments a une importance.

- insertion : si le tableau n'est pas remplie $$O(1)$$. Sinon $$O(n)$$ car il faut reconstruire un tableau plus grand.
- recherche : $$O(n)$$
- suppression : $$O(n)$$ ( car il faut d'abord trouver l'élement puis décaler les éléments les plus à droites)


#### Tableau trié : 

Ce type de tableau est utilisé lorsque l'ordre d'apparition des éléments n'a pas une importance.

- insertion : $$O(n)$$ 
- recherche : $$O(log(n))$$ (recherche par dichotomie)
- suppression : $$O(n)$$


### Listes

Une liste est une succession d'éléments, en quantité non défini. Chaque élément est constitué d'une donnée et de l'endroit où se trouve la donnée suivante.
Toutes listes se finissent par un élément ne possédant pas de successeur.

Les listes seront utilisés lorsque l'on ne connaît pas le nombre d'éléments à l'avance ou si l'on utilise des algorithmes récursifs.

#### Notations

Pour pouvoir manipuler les listes ont utilisera les notations suivantes :
- **[]** : liste vide
- $$[x_0, x_1, ..., x_n]$$ : c'est la liste des éléments $$x_0, x_1, ..., x_n$$
- **hd** : head, la tête de la liste, soit le premier élément. Si la liste est vide il n'y a pas de premier élément.
- **tl** : tail, la queue de la liste, ces la listes composé de tous les élément sauf de la tête.
- **+** : opérateur de concaténation. Par exemple L=hd(L) + tl(L)

#### Complexité des opérations

- insertion : $$O(1)$$ (l'élément insérer devient la tête). $$O(n)$$ si la liste est triée.
- recherche : $$O(n)$$
- suppression : $$O(n)$$


~~~ question

Soient L une liste et x un élément.
Donner des algorithmes récursives pour l'insertion, la recherche et la suppression.

~~~

~~~ answer

```
Insertion(L, x) = return (x+L);
```

```
Suppression(L, x)  
|Si L == [] alors return []
|Sinon  
| |Si hd(L) == x alors return(Suppression(tl(L),x))  
| |Sinon return ( hd(L) + Suppression(tl(L), x) )
```

```
Rechercher(L, x)
|Si L == [] alors return false
|Sinon 
| |Si hd(L) == x alors return true
| |Sinon return Rechercher(tl(L), x)
```

~~~


### Arbres

Rechercher un élément dans une liste prend du temps si il y a plein d’éléments comme pour un dictionnaire. Les arbres permettent de régler ce problème.

Un arbre est composé de noeuds. Tout les noeuds N possède une valeur (ou étiquette) noté N.E. Chaque noeud peut posséder des fils. Les fils d'un noeud sont des arbres, un noeud sans fils est une feuille. Un noeud N est le père d'un noeud n si n est un fils de N. Un noeud sans fils est une racine.




#### ABR (Arbre Binaire de Recherche)

Un arbre binaire est un arbre dont chaque noeuds possède au plus deux fils, un fils gauche et un fils droit, notées respectivement N.G et N.D pour un noeud N.

Un arbre binaire de recherche (abr) est défini inductivement par :
- une feuille est un abr
- si A.G et A.D sont des abr et A.E est plus grand que toutes les étiquettes de A.G et plus petit que toutes les étiquettes de A.D alors A est un abr.

Pour un abr les opérations de recherche, insertion et suppresion ont pour coût :
- insertion : pire cas $$O(n)$$, en moyenne $$O(log(n))$$
- recherche : pire cas $$O(n)$$, en moyenne $$O(log(n))$$
- suppression : pire cas $$O(n)$$, en moyenne $$O(log(n))$$

Le pire cas arrive si l'arbre est presque linéaire (presque tout les noeuds ont un seul fils).

#### AVL ou arbre équilibré

Les AVL sont des abr particuliers qui permettent d'avoir les opérations d'insertion, recherche, suppression en $$O(log(n))$$.


